{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575cd194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laden van 10.0% sample uit Data\\20250820163000_stream.tomtom.analyze-sail.parquet...\n",
      "Ruwe data succesvol geladen en gesampled!\n",
      "Verwerken van verkeersdata uit de '_value' kolom...\n",
      "Succesvol 225,582 wegsegment-datapunten verwerkt.\n",
      "\n",
      "Aggregeren van verkeersdata: berekenen van gemiddelde drukte per wegvak...\n",
      "Data geaggregeerd naar 10,742 unieke wegvakken.\n",
      "\n",
      "Laden van kaartdata uit shapefile: C:\\Users\\gerri\\Downloads\\01-12-2024\\01-12-2024\\Wegvakken\\Wegvakken.shp...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "# --- Configuratie ---\n",
    "# Pad naar je Parquet-bestand met verkeersdata.\n",
    "TOMTOM_FILE_PATH = os.path.join('Data', '20250820163000_stream.tomtom.analyze-sail.parquet')\n",
    "# Pad naar het SHP-bestand. AANGEPAST naar het volledige pad dat je hebt opgegeven.\n",
    "# De 'r' voor de string zorgt ervoor dat de backslashes in het Windows-pad correct worden gelezen.\n",
    "SHAPEFILE_PATH = r'C:\\Users\\gerri\\Downloads\\01-12-2024\\01-12-2024\\Wegvakken\\Wegvakken.shp'\n",
    "# We nemen een 10% sample van de data om geheugenproblemen te voorkomen.\n",
    "SAMPLE_FRACTION = 0.1\n",
    "# Dit is de naam van de kolom in het shapefile die de ID's van de wegvakken bevat.\n",
    "# 'WVK_ID' is een veelvoorkomende naam in het NWB. Pas dit aan als het anders heet.\n",
    "SHAPEFILE_ID_COL = 'WVK_ID'\n",
    "\n",
    "\n",
    "# --- Helper Functie om TomTom Data te Verwerken ---\n",
    "def parse_tomtom_data(value_string):\n",
    "    \"\"\"\n",
    "    Verwerkt de JSON-string uit de '_value' kolom en de CSV-data daarbinnen.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_index = value_string.find('{')\n",
    "        if start_index == -1: return None\n",
    "        data = json.loads(value_string[start_index:])\n",
    "        \n",
    "        if 'data' in data and isinstance(data['data'], str):\n",
    "            csv_string = data['data']\n",
    "            return pd.read_csv(StringIO(csv_string))\n",
    "            \n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# --- Hoofdscript ---\n",
    "try:\n",
    "    # --- 1. Laad en verwerk TomTom Verkeersdata ---\n",
    "    print(f\"Laden van {SAMPLE_FRACTION*100}% sample uit {TOMTOM_FILE_PATH}...\")\n",
    "    parquet_file = pq.ParquetFile(TOMTOM_FILE_PATH)\n",
    "    list_of_sampled_dfs = []\n",
    "    for batch in parquet_file.iter_batches():\n",
    "        chunk_df = batch.to_pandas()\n",
    "        list_of_sampled_dfs.append(chunk_df.sample(frac=SAMPLE_FRACTION))\n",
    "    df_raw = pd.concat(list_of_sampled_dfs, ignore_index=True)\n",
    "    print(\"Ruwe data succesvol geladen en gesampled!\")\n",
    "\n",
    "    print(\"Verwerken van verkeersdata uit de '_value' kolom...\")\n",
    "    parsed_dfs = df_raw['_value'].apply(parse_tomtom_data)\n",
    "    parsed_dfs.dropna(inplace=True)\n",
    "    df_traffic = pd.concat(parsed_dfs.tolist(), ignore_index=True)\n",
    "    print(f\"Succesvol {len(df_traffic):,} wegsegment-datapunten verwerkt.\")\n",
    "    \n",
    "    # --- Aggregeer de verkeersdata ---\n",
    "    print(\"\\nAggregeren van verkeersdata: berekenen van gemiddelde drukte per wegvak...\")\n",
    "    df_traffic_agg = df_traffic.groupby('id')['traffic_level'].mean().reset_index()\n",
    "    print(f\"Data geaggregeerd naar {len(df_traffic_agg):,} unieke wegvakken.\")\n",
    "\n",
    "    # --- 2. Laad de Kaartdata (Shapefile) ---\n",
    "    print(f\"\\nLaden van kaartdata uit shapefile: {SHAPEFILE_PATH}...\")\n",
    "    gdf = gpd.read_file(SHAPEFILE_PATH)\n",
    "    print(\"Kaartdata succesvol geladen!\")\n",
    "    \n",
    "    # --- Filter kaartdata op Amsterdam ---\n",
    "    print(\"Coördinatensysteem van shapefile omzetten...\")\n",
    "    gdf = gdf.to_crs(epsg=44326) # Eerst omzetten naar standaard lat/lon\n",
    "    \n",
    "    print(\"Filteren van wegvakken binnen de bounding box van Amsterdam...\")\n",
    "    # Definieer de bounding box voor de regio Amsterdam\n",
    "    min_lon, min_lat = 4.72, 52.28\n",
    "    max_lon, max_lat = 5.08, 52.43\n",
    "    gdf_amsterdam = gdf.cx[min_lon:max_lon, min_lat:max_lat]\n",
    "    print(f\"Filteren voltooid: {len(gdf_amsterdam):,} wegvakken over in de regio Amsterdam.\")\n",
    "\n",
    "    \n",
    "    # --- 3. Koppel de dataframes ---\n",
    "    if SHAPEFILE_ID_COL not in gdf_amsterdam.columns:\n",
    "        raise KeyError(f\"KRITISCHE FOUT: De ID-kolom '{SHAPEFILE_ID_COL}' is niet gevonden in het shapefile. \"\n",
    "                       f\"Pas de 'SHAPEFILE_ID_COL' variabele bovenaan het script aan.\")\n",
    "\n",
    "    print(f\"\\nKoppelen van verkeersdata aan de gefilterde kaartdata...\")\n",
    "    gdf_amsterdam[SHAPEFILE_ID_COL] = pd.to_numeric(gdf_amsterdam[SHAPEFILE_ID_COL], errors='coerce')\n",
    "    df_traffic_agg['id'] = pd.to_numeric(df_traffic_agg['id'], errors='coerce')\n",
    "    \n",
    "    # We mergen nu met de veel kleinere, gefilterde GeoDataFrame\n",
    "    merged_gdf = gdf_amsterdam.merge(df_traffic_agg, left_on=SHAPEFILE_ID_COL, right_on='id')\n",
    "    print(f\"Succesvol {len(merged_gdf):,} wegvakken gekoppeld!\")\n",
    "\n",
    "    if len(merged_gdf) == 0:\n",
    "         print(\"\\nWAARSCHUWING: Er konden geen wegvakken worden gekoppeld. Controleer of de ID-kolommen ('id' en de gekozen SHAPEFILE_ID_COL) overeenkomen.\")\n",
    "    else:\n",
    "        # --- 4. Creëer de Choropleth Kaart ---\n",
    "        print(\"Genereren van de verkeerskaart...\")\n",
    "        \n",
    "        # AANPASSING: Converteer datumkolommen naar een string voor JSON-compatibiliteit.\n",
    "        for col in merged_gdf.columns:\n",
    "            if pd.api.types.is_datetime64_any_dtype(merged_gdf[col]):\n",
    "                print(f\"Datumkolom '{col}' wordt omgezet naar string...\")\n",
    "                merged_gdf[col] = merged_gdf[col].astype(str)\n",
    "\n",
    "        # Converteer de gefusioneerde data naar een expliciete GeoJSON.\n",
    "        merged_gdf_json = json.loads(merged_gdf.to_json())\n",
    "\n",
    "        fig = px.choropleth_mapbox(\n",
    "            merged_gdf,\n",
    "            geojson=merged_gdf_json,\n",
    "            locations=SHAPEFILE_ID_COL,\n",
    "            featureidkey=f\"properties.{SHAPEFILE_ID_COL}\",\n",
    "            color=\"traffic_level\",\n",
    "            color_continuous_scale=\"RdYlGn_r\",\n",
    "            mapbox_style=\"carto-positron\",\n",
    "            center={\"lat\": 52.3676, \"lon\": 4.9041},\n",
    "            zoom=11,\n",
    "            opacity=0.8,\n",
    "            title=\"Gemiddelde Verkeersdrukte per Wegvak in Amsterdam\",\n",
    "            labels={\"traffic_level\": \"Gem. Drukte\"},\n",
    "            height=800\n",
    "        )\n",
    "        fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "        fig.show()\n",
    "        print(\"\\nVisualisatie gegenereerd! Controleer je web browser.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"--- FOUT: Bestand niet gevonden ---\")\n",
    "    print(f\"Het script kon een bestand niet vinden: {e.filename}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Er is een onverwachte fout opgetreden: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
